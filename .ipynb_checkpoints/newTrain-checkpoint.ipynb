{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from common import GENRES\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Lambda, Dropout, Activation, \\\n",
    "        TimeDistributed, Convolution1D, MaxPooling1D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "from optparse import OptionParser\n",
    "from sys import stderr, argv\n",
    "import os\n",
    "\n",
    "SEED = 42\n",
    "N_LAYERS = 3\n",
    "FILTER_LENGTH = 5\n",
    "CONV_FILTER_COUNT = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_COUNT = 500\n",
    "MODEL_PATH=\"\"\n",
    "TRACK_PATH=\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "import os\n",
    "path=\"./\"\n",
    "\n",
    "tensorboard_path=os.path.join(path,\"tensorboard\")\n",
    "os.makedirs(tensorboard_path, exist_ok=True)\n",
    "tb = TensorBoard(log_dir=tensorboard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model_path):\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    (x_train, x_val, y_train, y_val) = train_test_split(x, y, test_size=0.3,\n",
    "            random_state=SEED)\n",
    "    #700 647 128\n",
    "    print(\"X\",x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print('Building model...',x_train.shape[0],x_train.shape[1],x_train.shape[2])\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(512, activation='relu', input_shape=(647,128)))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    print(model.summary())\n",
    "    print('Training...')\n",
    "    model.fit(\n",
    "        x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
    "        validation_data=(x_val, y_val), verbose=1, callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                model_path, save_best_only=True, monitor='val_acc', verbose=1\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_acc', factor=0.5, patience=10, min_delta=0.01,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Conv2D, BatchNormalization, Lambda\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Conv2D, BatchNormalization, Lambda\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "N_LAYERS = 3\n",
    "FILTER_LENGTH = 5\n",
    "CONV_FILTER_COUNT = 56\n",
    "BATCH_SIZE = 32\n",
    "LSTM_COUNT = 96\n",
    "EPOCH_COUNT = 500\n",
    "NUM_HIDDEN = 64\n",
    "L2_regularization = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_recurrent_model_build(model_input):\n",
    "    print('Building model...')\n",
    "    layer = model_input\n",
    "\n",
    "    ### 3 1D Convolution Layers\n",
    "    for i in range(N_LAYERS):\n",
    "        # give name to the layers\n",
    "        layer = Conv1D(\n",
    "                filters=CONV_FILTER_COUNT,\n",
    "                kernel_size=FILTER_LENGTH,\n",
    "                kernel_regularizer=regularizers.l2(L2_regularization),  # Tried 0.001\n",
    "                name='convolution_' + str(i + 1)\n",
    "            )(layer)\n",
    "        layer = BatchNormalization(momentum=0.9)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling1D(2)(layer)\n",
    "        layer = Dropout(0.4)(layer)\n",
    "\n",
    "    ## LSTM Layer\n",
    "    layer = LSTM(LSTM_COUNT, return_sequences=False)(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "\n",
    "    ## Dense Layer\n",
    "    layer = Dense(NUM_HIDDEN, kernel_regularizer=regularizers.l2(L2_regularization), name='dense1')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "\n",
    "    ## Softmax Output\n",
    "    layer = Dense(num_classes)(layer)\n",
    "    layer = Activation('softmax', name='output_realtime')(layer)\n",
    "    model_output = layer\n",
    "    model = Model(model_input, model_output)\n",
    "\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model2(data, model_path):\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    (x_train, x_val, y_train, y_val) = train_test_split(x, y, test_size=0.3,random_state=SEED)\n",
    "    n_features = x_train.shape[2]\n",
    "    input_shape = (None, n_features)\n",
    "    print(\"X\",x_train.shape)\n",
    "    print(\"Y \",y_train.shape)\n",
    "\n",
    "    model_input = Input(input_shape, name='input')\n",
    "    print(\"Test 1\",input_shape)\n",
    "    model = conv_recurrent_model_build(model_input)\n",
    "\n",
    "#     tb_callback = TensorBoard(log_dir='./logs/4', histogram_freq=1, batch_size=32, write_graph=True, write_grads=False,\n",
    "#                               write_images=False, embeddings_freq=0, embeddings_layer_names=None,\n",
    "#                               embeddings_metadata=None)\n",
    "#    checkpoint_callback = ModelCheckpoint('./models/crnn/weights.best.h5', monitor='val_acc', verbose=1,\n",
    "#                                          save_best_only=True, mode='max')\n",
    "\n",
    "    reducelr_callback = ReduceLROnPlateau(\n",
    "                monitor='val_acc', factor=0.5, patience=10, min_delta=0.01,\n",
    "                verbose=1\n",
    "            )\n",
    "#    callbacks_list = [checkpoint_callback, reducelr_callback]\n",
    "\n",
    "    # Fit the model and get training history.\n",
    "    '''\n",
    "    print('Training...')\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
    "                        validation_data=(x_val, y_val), verbose=1)\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    history=model.fit(\n",
    "    x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
    "        validation_data=(x_val, y_val), verbose=1, callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                model_path, save_best_only=True, monitor='val_acc', verbose=1\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_acc', factor=0.5, patience=10, min_delta=0.01,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    '''\n",
    "    history=model.fit(\n",
    "        x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
    "        validation_data=(x_val, y_val), verbose=1, callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                model_path, save_best_only=True, monitor='val_acc', verbose=1\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_acc', factor=0.5, patience=10, min_delta=0.01,\n",
    "                verbose=1\n",
    "            ),\n",
    "            tb\n",
    "        ]\n",
    "    )\n",
    "    return model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_summary_stats(history):\n",
    "    # List all data in history\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (700, 647, 128)\n",
      "Y  (700, 10)\n",
      "Test 1 (None, 128)\n",
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "convolution_1 (Conv1D)       (None, None, 56)          35896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 56)          224       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 56)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 56)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 56)          0         \n",
      "_________________________________________________________________\n",
      "convolution_2 (Conv1D)       (None, None, 56)          15736     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 56)          224       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, None, 56)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 56)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 56)          0         \n",
      "_________________________________________________________________\n",
      "convolution_3 (Conv1D)       (None, None, 56)          15736     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 56)          224       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, None, 56)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 56)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, None, 56)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 96)                58752     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 64)                6208      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "output_realtime (Activation) (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 133,650\n",
      "Trainable params: 133,314\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 6s 9ms/step - loss: 2.4568 - acc: 0.2100 - val_loss: 2.2255 - val_acc: 0.3067\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30667, saving model to /home/infinity/MGR/genre-recognition-master/models/model.h5\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 5s 8ms/step - loss: 2.1697 - acc: 0.3214 - val_loss: 2.0693 - val_acc: 0.3533\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.30667 to 0.35333, saving model to /home/infinity/MGR/genre-recognition-master/models/model.h5\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 5s 7ms/step - loss: 2.0322 - acc: 0.3886 - val_loss: 2.0022 - val_acc: 0.3600\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.35333 to 0.36000, saving model to /home/infinity/MGR/genre-recognition-master/models/model.h5\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 5s 7ms/step - loss: 1.9369 - acc: 0.4029 - val_loss: 1.8516 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.36000 to 0.44000, saving model to /home/infinity/MGR/genre-recognition-master/models/model.h5\n",
      "Epoch 5/100\n",
      "320/700 [============>.................] - ETA: 2s - loss: 1.7287 - acc: 0.5062"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = OptionParser()\n",
    "    parser.add_option('-d', '--data_path', dest='data_path',\n",
    "            #default=os.path.join(os.path.dirname(__file__),'data/data.pkl'),\n",
    "            default=os.path.join(os.getcwd(), 'data/data.pkl'),\n",
    "            help='path to the data pickle', metavar='DATA_PATH')\n",
    "    parser.add_option('-m', '--model_path', dest='model_path',\n",
    "            default=os.path.join(os.getcwd(),\n",
    "                'models/model.h5'),\n",
    "            help='path to the output model HDF5 file', metavar='MODEL_PATH')\n",
    "    options, args = parser.parse_args()\n",
    "\n",
    "    with open(options.data_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "\n",
    "    #train_model(data, options.model_path)\n",
    "    model, history=train_model2(data, options.model_path)\n",
    "\n",
    "    show_summary_stats(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and validation loss\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import keras\n",
    "\n",
    "keras.backend.set_session(\n",
    "    tf_debug.TensorBoardDebugWrapperSession(tf.Session(), \"infinity-Inspiron-15-7000-Gaming:6007\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
